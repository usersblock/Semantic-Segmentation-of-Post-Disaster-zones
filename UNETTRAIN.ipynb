{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88943e3-eae9-4430-960f-3946b83a886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thanh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\thanh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "C:\\Users\\thanh/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "None\n",
      "C:\\Users\\thanh/.cache\\torch\\hub\\checkpoints\\vgg19_bn-c79401a0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thanh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from utils.data_loading import SatelliteDataset\n",
    "from utils.dice_score import dice_loss\n",
    "from evaluate import evaluate\n",
    "from unet import SiamUNetConCResnet50,vgg19nobn_unetdouble,VGG16Unet,resnet_unet,resnet_siamunet,SiamUNetDiffVgg19Space, SiamUNetFullConCVgg19,SiamUNetDiffVgg19,UNETResnet50,UNet,SiamUNet,SiamUNetConC,SiamUNetDiff, SiamUNetConCVgg19, VGG19Unet,vgg19bn_unet,vgg19nobn_unet,vgg16bn_unet, UNetWithResnet50Encoder, UNetWithVgg19BnEncoder, SiameseUNetWithResnet50Encoder, SiamUnet_diff_Full, SiameseUNetV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses.focal import FocalLoss\n",
    "import numpy as np\n",
    "from torchmetrics import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53717d7a-d5ef-4065-8aa4-9cc58f944ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Image512\\\\')\n",
    "post_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Label512\\\\')\n",
    "pre_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Image512\\\\')\n",
    "pre_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Label512\\\\')\n",
    "post_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Image512\\\\')\n",
    "post_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Label512\\\\')\n",
    "pre_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Image512\\\\')\n",
    "pre_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Label512\\\\')\n",
    "dir_checkpoint = Path('./checkpoints/Vgg19SiamConc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12971e28-05f2-4dc1-84a9-11c032bbebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "closs = nn.CrossEntropyLoss()\n",
    "\n",
    "floss = FocalLoss(mode = 'multiclass',\n",
    "                alpha = None,\n",
    "                gamma = 2.0,\n",
    "                ignore_index = None,\n",
    "                reduction = \"mean\",\n",
    "                normalized = False,\n",
    "                reduced_threshold = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f09306-c13e-4223-aed1-a9132cf186a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights():\n",
    "    train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[1,1], True, True, 0, None, 0, 0], probabilities = [.5,.5,.5,0,0,0,0],increase = 8397,mask_suffix = '.png')\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    train_loader = DataLoader(train, shuffle=True, **loader_args)\n",
    "    classes = torch.zeros(5)\n",
    "    with tqdm(total=len(train_loader), unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            image = batch['mask'].int()\n",
    "            count = torch.bincount(torch.flatten(image),minlength = 5)\n",
    "            classes = classes.add(count)\n",
    "            pbar.update(image.shape[0])\n",
    "    return torch.div(classes,torch.sum(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942d4f06-3c0c-4b6e-9427-89040918aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net,\n",
    "              device,\n",
    "              start_epoch: int = 1,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              train_percent: float = 0.5,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              ampbool: bool = False,\n",
    "              traintype: str = 'post',\n",
    "              gradient_clipping: float = 1.0):\n",
    "    # 1. Create dataset\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)    \n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    #optimizer = optim.AdamW(net.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-6, momentum=0.9, foreach=True)\n",
    "    #scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 5, 1,eta_min = learning_rate/100)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,6,9,12,15,18,19,20, 33, 47, 50, 60, 70, 90, 110, 130, 150, 170, 180, 190], gamma=0.5)\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=ampbool)\n",
    "    criterion = closs\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(start_epoch, start_epoch + epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        nancount = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preimage, postimage, post_masks, pre_masks = batch['preimage'], batch['image'], batch['mask'], batch['premask']\n",
    "\n",
    "                preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "                postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "                post_masks = post_masks.to(device=device, dtype=torch.long)\n",
    "                pre_masks = pre_masks.to(device=device, dtype=torch.long)\n",
    "                with torch.cuda.amp.autocast(enabled = ampbool):\n",
    "                    masks_pred = None\n",
    "                    if(traintype == 'both'):\n",
    "                        masks_pred = net(preimage,postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    if(traintype == 'pre'):\n",
    "                        masks_pred = net(preimage)\n",
    "                        loss = criterion(masks_pred, pre_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(pre_masks, 2).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    if(traintype == 'post'):\n",
    "                        masks_pred = net(postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    \n",
    "                grad_scaler.scale(loss).backward()\n",
    "                #torch.nn.utils.clip_grad_norm_(net.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "                pbar.update(postimage.shape[0])\n",
    "                global_step += 1\n",
    "                if(math.isnan(loss.item())):\n",
    "                    epoch_loss+=0\n",
    "                    nancount +=1\n",
    "                else:\n",
    "                    epoch_loss += loss.item()\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "                        \n",
    "        val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = ampbool,traintype = traintype)\n",
    "        scheduler.step(val_score)\n",
    "        print(val_score)\n",
    "        print(val_classes)\n",
    "        print(val_loss)\n",
    "        print(epoch_loss/n_train)\n",
    "        print(nancount)\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / 'branch12checkpoint_epoch_branch_{}.pth'.format(epoch)))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2ac268-7ce1-40bc-8a15-f222eff06b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 5\n",
    "bilinear = True\n",
    "loadstate = True\n",
    "load = './checkpoints/Vgg19SiamConc/checkpoint_epoch12.pth'\n",
    "start_epoch = 13\n",
    "epochs = 20\n",
    "batch_size = 1\n",
    "lr = 1e-6\n",
    "scale = 1\n",
    "train =0.15259598603*2\n",
    "val = .50\n",
    "ampbool = True\n",
    "save_checkpoint = True\n",
    "traintype = 'both'\n",
    "gradclip = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77107f00-2494-4bb0-9cbd-ee82574c6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionmatrix(pred,true):\n",
    "    result = np.zeros((5,5))\n",
    "    for i in range(true.shape[1]):\n",
    "        for j in range(true.shape[2]):\n",
    "            result[true[0][i][j]][pred[0][i][j]] +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac114e3-23f2-49ef-bfcb-0a915104bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelconfusionmatrix(filepath,net,train_percent,val_percent):\n",
    "    device = 'cuda'\n",
    "    net.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    net.to(device=device)\n",
    "    net.eval()\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args) \n",
    "    resulttrain = torch.zeros(5,5).to(device)\n",
    "    resultval = torch.zeros(5,5).to(device)\n",
    "\n",
    "    num_val_batches = len(val_loader)\n",
    "    num_train_batches = len(train_loader)\n",
    "    confmat = ConfusionMatrix(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    with tqdm(total=num_train_batches, desc='train', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resulttrain += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resulttrain)\n",
    "    with tqdm(total=num_val_batches, desc='validation', unit='img') as pbar:\n",
    "        for batch in val_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resultval += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resultval)\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return resulttrain,resultval\n",
    "    return resulttrain,resultval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a4f7b2-0d98-4b4e-aedb-e4def82605b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateFolder(folderpath,net,train_percent,val_percent):\n",
    "    in_files = [folderpath + s for s in os.listdir(folderpath)]\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    \n",
    "    for i in in_files:\n",
    "        net.load_state_dict(torch.load(i, map_location=device))\n",
    "        net.to(device=device)\n",
    "        #val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        train_score, train_classes,train_loss = evaluate(net,dataloader = train_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        print('Train: ' + i)\n",
    "        print(train_score)\n",
    "        print(train_loss)\n",
    "        #print('Validation: ' + i)\n",
    "        #print(val_score)\n",
    "        #print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35580102-25ef-42d1-b220-2c9322623a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "C:\\Users\\thanh/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n"
     ]
    }
   ],
   "source": [
    "net = SiamUNetConCVgg19()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1dd16c5-6fab-4c6b-8e60-96c2babd59e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████████| 2797/2797 [06:04<00:00,  7.67img/s, loss (batch)=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch1.pth\n",
      "tensor(0.7376, device='cuda:0')\n",
      "1.0003046989440918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [06:02<00:00,  7.72img/s, loss (batch)=0.915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch10.pth\n",
      "tensor(0.7143, device='cuda:0')\n",
      "0.9154515862464905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████████| 2797/2797 [06:18<00:00,  7.39img/s, loss (batch)=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch11.pth\n",
      "tensor(0.6655, device='cuda:0')\n",
      "0.9999935030937195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [06:13<00:00,  7.49img/s, loss (batch)=0.823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch12.pth\n",
      "tensor(0.7010, device='cuda:0')\n",
      "0.8234946131706238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [06:16<00:00,  7.44img/s, loss (batch)=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch13.pth\n",
      "tensor(0.6159, device='cuda:0')\n",
      "0.787083625793457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [06:13<00:00,  7.50img/s, loss (batch)=0.883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch14.pth\n",
      "tensor(0.6730, device='cuda:0')\n",
      "0.8827695846557617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|████████████████████████████████████████████| 2797/2797 [06:13<00:00,  7.49img/s, loss (batch)=0.0724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch15.pth\n",
      "tensor(0.7632, device='cuda:0')\n",
      "0.07237060368061066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████████████████████████████████████████| 2797/2797 [06:14<00:00,  7.46img/s, loss (batch)=0.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch16.pth\n",
      "tensor(0.7851, device='cuda:0')\n",
      "0.4397904574871063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████████████████████████████████████████| 2797/2797 [06:04<00:00,  7.68img/s, loss (batch)=0.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch17.pth\n",
      "tensor(0.7704, device='cuda:0')\n",
      "0.1397068202495575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|███████████████████████████████████████████| 2797/2797 [06:01<00:00,  7.73img/s, loss (batch)=5.42e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch18.pth\n",
      "tensor(0.7951, device='cuda:0')\n",
      "5.424022674560547e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [06:02<00:00,  7.71img/s, loss (batch)=0.247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch19.pth\n",
      "tensor(0.7925, device='cuda:0')\n",
      "0.24695277214050293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|███████████████████████████████████████████████| 2797/2797 [05:30<00:00,  8.45img/s, loss (batch)=1.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch2.pth\n",
      "tensor(0.7396, device='cuda:0')\n",
      "1.2958807945251465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████████████████████████████████████| 2797/2797 [05:46<00:00,  8.07img/s, loss (batch)=0.000524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch20.pth\n",
      "tensor(0.7839, device='cuda:0')\n",
      "0.0005237460136413574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████████| 2797/2797 [05:50<00:00,  7.97img/s, loss (batch)=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch3.pth\n",
      "tensor(0.7717, device='cuda:0')\n",
      "1.0000234842300415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [05:47<00:00,  8.05img/s, loss (batch)=0.935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch4.pth\n",
      "tensor(0.7723, device='cuda:0')\n",
      "0.9350355863571167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████████████████████████████████████████| 2797/2797 [05:54<00:00,  7.88img/s, loss (batch)=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch5.pth\n",
      "tensor(0.7744, device='cuda:0')\n",
      "1.2187442779541016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [06:02<00:00,  7.72img/s, loss (batch)=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch6.pth\n",
      "tensor(0.7374, device='cuda:0')\n",
      "0.8170241713523865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [06:02<00:00,  7.71img/s, loss (batch)=0.878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch7.pth\n",
      "tensor(0.6391, device='cuda:0')\n",
      "0.8779056072235107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [05:50<00:00,  7.99img/s, loss (batch)=0.784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch8.pth\n",
      "tensor(0.6402, device='cuda:0')\n",
      "0.7842162847518921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|█████████████████████████████████████████████| 2797/2797 [05:53<00:00,  7.91img/s, loss (batch)=0.842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ./checkpoints/Vgg19SiamConc/checkpoint_epoch9.pth\n",
      "tensor(0.6176, device='cuda:0')\n",
      "0.8423086404800415\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './checkpoints/Vgg19SiamConc/New folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mEvaluateFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./checkpoints/Vgg19SiamConc/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mEvaluateFolder\u001b[1;34m(folderpath, net, train_percent, val_percent)\u001b[0m\n\u001b[0;32m     27\u001b[0m loader_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)        \n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m in_files:\n\u001b[1;32m---> 30\u001b[0m     net\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     31\u001b[0m     net\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m#val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = True,traintype = 'both')\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './checkpoints/Vgg19SiamConc/New folder'"
     ]
    }
   ],
   "source": [
    "EvaluateFolder('./checkpoints/Vgg19SiamConc/',net,train,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5296ca72-e1c5-4b16-bbfd-a3acf043de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "384af319-b598-472f-aa56-ca7f0f290cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in net.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in net.buffers()])\n",
    "mem = mem_params + mem_bufs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d215f12-c88c-409a-aa6b-f4c16deff94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149892372"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0478b74-66e6-482c-b4d5-33c91751a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "C:\\Users\\thanh/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|████████████████████████████████████████████████| 2797/2797 [08:08<00:00,  5.73img/s, loss (batch)=1]\n",
      "validation: 100%|███████████████████████████████████████████████| 466/466 [00:56<00:00,  8.20img/s, loss (batch)=0.917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4718, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "0.9166298508644104\n",
      "0.9219577716937183\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|█████████████████████████████████████████████| 2797/2797 [07:53<00:00,  5.91img/s, loss (batch)=0.99]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:56<00:00,  8.22img/s, loss (batch)=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5170, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "0.990046501159668\n",
      "0.9131598653305757\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|█████████████████████████████████████████████| 2797/2797 [07:54<00:00,  5.89img/s, loss (batch)=0.81]\n",
      "validation: 100%|███████████████████████████████████████████████| 466/466 [00:55<00:00,  8.35img/s, loss (batch)=0.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5693, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "0.8910744190216064\n",
      "0.9043296857799936\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|█████████████████████████████████████████████| 2797/2797 [07:54<00:00,  5.89img/s, loss (batch)=1.01]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:54<00:00,  8.50img/s, loss (batch)=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4914, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.0412195920944214\n",
      "0.899045032765723\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|████████████████████████████████████████████| 2797/2797 [07:54<00:00,  5.90img/s, loss (batch)=0.375]\n",
      "validation: 100%|███████████████████████████████████████████████| 466/466 [00:55<00:00,  8.42img/s, loss (batch)=0.922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5144, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "0.9215644001960754\n",
      "0.8917508406173684\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|████████████████████████████████████████████████| 2797/2797 [07:54<00:00,  5.90img/s, loss (batch)=1]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:56<00:00,  8.29img/s, loss (batch)=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5103, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.079857587814331\n",
      "0.8863733318668627\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|████████████████████████████████████████████████| 2797/2797 [07:52<00:00,  5.92img/s, loss (batch)=0]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:55<00:00,  8.45img/s, loss (batch)=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6297, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.050462007522583\n",
      "0.5097883359253044\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|█████████████████████████████████████████████| 2797/2797 [07:51<00:00,  5.93img/s, loss (batch)=8e-5]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:55<00:00,  8.34img/s, loss (batch)=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6097, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.0645313262939453\n",
      "0.3462128148014295\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/20: 100%|████████████████████████████████████████████| 2797/2797 [07:50<00:00,  5.94img/s, loss (batch)=0.609]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:56<00:00,  8.31img/s, loss (batch)=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6505, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.0193891525268555\n",
      "0.32107247223243157\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/20: 100%|█████████████████████████████████████████████| 2797/2797 [07:56<00:00,  5.87img/s, loss (batch)=1.04]\n",
      "validation: 100%|███████████████████████████████████████████████| 466/466 [00:57<00:00,  8.13img/s, loss (batch)=0.984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6305, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "0.9844585657119751\n",
      "0.31575716390851505\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/20: 100%|████████████████████████████████████████████| 2797/2797 [07:53<00:00,  5.91img/s, loss (batch)=0.541]\n",
      "validation: 100%|███████████████████████████████████████████████| 466/466 [00:55<00:00,  8.41img/s, loss (batch)=0.666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6406, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "0.6661007404327393\n",
      "0.30372589069405626\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/20: 100%|█████████████████████████████████████████████| 2797/2797 [07:51<00:00,  5.93img/s, loss (batch)=1.39]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:54<00:00,  8.55img/s, loss (batch)=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6459, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.1200270652770996\n",
      "0.30154080308732717\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/20: 100%|███████████████████████████████████████████| 2797/2797 [07:51<00:00,  5.93img/s, loss (batch)=0.0948]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:56<00:00,  8.22img/s, loss (batch)=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6263, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.0380072593688965\n",
      "0.2853890413443052\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/20: 100%|██████████████████████████████████████████| 2797/2797 [07:53<00:00,  5.90img/s, loss (batch)=5.48e-6]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:55<00:00,  8.45img/s, loss (batch)=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6396, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.2479231357574463\n",
      "0.2831485341348002\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/20: 100%|█████████████████████████████████████████████| 2797/2797 [07:56<00:00,  5.87img/s, loss (batch)=1.63]\n",
      "validation: 100%|████████████████████████████████████████████████| 466/466 [00:55<00:00,  8.34img/s, loss (batch)=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6248, device='cuda:0')\n",
      "[0, 0, 0, 0, 0]\n",
      "1.44805908203125\n",
      "0.2842888791909229\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/20:  68%|█████████████████████████████▊              | 1898/2797 [05:22<02:32,  5.91img/s, loss (batch)=0.618]"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    #net = SiamUNetDiff()\n",
    "    #net = SiamUNetConC()\n",
    "    #net = SiameseUNetWithResnet50Encoder()\n",
    "    #net = SiamUnet_diff_Full(3,5)\n",
    "    #net = UNetWithResnet50Encoder(5,'custom','./checkpoints/Resnet50ContrastiveWeight/checkpoint_epoch0.pth')\n",
    "    #net = UNet(out_classes=classes, up_sample_mode='conv_transpose',batch_norm=False)\n",
    "    #net = SiameseUNet(n_channels=3, n_classes = classes, bilinear=bilinear)\n",
    "    #net = UNetVgg19V2(out_classes=classes, up_sample_mode='conv_transpose')\n",
    "    #net = vgg19bn_unet(5,True)\n",
    "    #net = vgg19nobn_unet(5,True)\n",
    "    #net = vgg19nobn_unetdouble(5,True)\n",
    "    #net = VGGUnet19nobnspace(out_channels = 5, pretrained = True)\n",
    "    #net = SiamUNetCombVgg19()\n",
    "    net = SiamUNetConCVgg19()\n",
    "    #net = resnet_unet()\n",
    "    #net = VGG16Unet(out_channels = 5)\n",
    "    #net = resnet_siamunet()\n",
    "    #net = SiamUNetDiffVgg19()\n",
    "    #net = SiamUNetFullConCVgg19()\n",
    "    #net = SiamUNetConCResnet50(True,5)\n",
    "    #net = UNETResnet50(True,2)\n",
    "    '''net = smp.Unet(\n",
    "        encoder_name='resnext101_32x8d',\n",
    "        encoder_depth=5,\n",
    "        encoder_weights='imagenet',\n",
    "        decoder_use_batchnorm=False,\n",
    "        decoder_channels=(1024,512,256,128, 64),\n",
    "        decoder_attention_type=None,\n",
    "        in_channels=3,\n",
    "        classes=5,\n",
    "        activation=None,\n",
    "        aux_params=None\n",
    "    )\n",
    "    '''\n",
    "    if loadstate:\n",
    "        net.load_state_dict(torch.load(load, map_location=device))\n",
    "        logging.info(f'Model loaded from {load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    train_net(net=net,\n",
    "                  start_epoch = start_epoch,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  learning_rate=lr,\n",
    "                  device=device,\n",
    "                  img_scale=scale,\n",
    "                  train_percent = train,\n",
    "                  val_percent=val,\n",
    "                  save_checkpoint = save_checkpoint,\n",
    "                  ampbool = ampbool,\n",
    "                  traintype = traintype,\n",
    "                  gradient_clipping=gradclip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7419f9-ef71-40ca-9b93-16198f542a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
