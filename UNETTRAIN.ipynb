{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88943e3-eae9-4430-960f-3946b83a886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data_loading import BasicDataset\n",
    "from utils.dice_score import dice_loss\n",
    "from evaluate import evaluate\n",
    "from unet import UNet\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses.dice import DiceLoss\n",
    "from segmentation_models_pytorch.losses.focal import FocalLoss\n",
    "from segmentation_models_pytorch.losses.tversky import TverskyLoss\n",
    "from segmentation_models_pytorch.losses.jaccard import JaccardLoss\n",
    "from segmentation_models_pytorch.losses.lovasz import LovaszLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818c45f2-b2fb-4e37-afba-6d95b28d9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_img = Path('.\\\\Dataset\\\\Tier1\\\\Post\\\\Image512\\\\')\n",
    "dir_mask = Path('.\\\\Dataset\\\\Tier1\\\\Post\\\\Label512\\\\')\n",
    "dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Image512\\\\')\n",
    "dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Label512\\\\')\n",
    "dir_checkpoint = Path('./checkpoints/MobileNet_V2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12971e28-05f2-4dc1-84a9-11c032bbebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "closs = nn.CrossEntropyLoss()\n",
    "dloss = DiceLoss(mode = 'multiclass',\n",
    "                 log_loss = False,\n",
    "                 from_logits = True,\n",
    "                 smooth = 0,\n",
    "                 eps = 1e-7)\n",
    "floss = FocalLoss(mode = 'multiclass',\n",
    "                alpha = None,\n",
    "                gamma = 1.0,\n",
    "                ignore_index = None,\n",
    "                reduction = \"mean\",\n",
    "                normalized = False,\n",
    "                reduced_threshold = None)\n",
    "tloss = TverskyLoss(mode = 'multiclass',\n",
    "        from_logits = True,\n",
    "        alpha = 0.6,\n",
    "        beta = 0.4,\n",
    "        gamma = 1.0)\n",
    "jloss = JaccardLoss(mode = 'multiclass',\n",
    "        from_logits = True,\n",
    "        eps = 1e-7)\n",
    "lloss = LovaszLoss(mode = 'multiclass',\n",
    "        per_image = False,\n",
    "        from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9173a90a-6762-41f7-ae23-e0d4e539a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net,\n",
    "              device,\n",
    "              start_epoch: int = 1,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              amp: bool = False):\n",
    "    # 1. Create dataset\n",
    "    try:\n",
    "        dataset = BasicDataset(dir_img, dir_mask, img_scale, values =  [1, False, False, 0, None, 0, 0], probabilities = [0,0,0,0,0,0,0],increase = 0,mask_suffix = '.png')\n",
    "        valdataset = BasicDataset(dir_val_img, dir_val_mask, img_scale, mask_suffix = '.png')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=1, pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(valdataset, shuffle=True,batch_size=1, num_workers=1, pin_memory=True)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    #experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "    #experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "    #                              val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale,\n",
    "    #                              amp=amp))\n",
    "\n",
    "    #logging.info(f'''Starting training:\n",
    "    #    Epochs:          {epochs}\n",
    "    #    Batch size:      {batch_size}\n",
    "    #    Learning rate:   {learning_rate}\n",
    "    #    Training size:   {n_train}\n",
    "    #    Validation size: {n_val}\n",
    "    #    Checkpoints:     {save_checkpoint}\n",
    "    #    Device:          {device}\n",
    "    #    Images scaling:  {img_scale}\n",
    "    #    Mixed Precision: {amp}\n",
    "    #''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion =closs\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(start_epoch, start_epoch + epochs):\n",
    "        print(epoch)\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "#                assert images.shape[1] == net.n_channels, \\\n",
    "#                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "#                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "#                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    masks_pred = net(images)\n",
    "\n",
    "#                    loss = criterion(masks_pred, true_masks) \\\n",
    "#                           + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
    "#                                       F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
    "#                                       multiclass=True)\n",
    "                    loss = criterion(masks_pred, true_masks)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                #experiment.log({\n",
    "                #    'train loss': loss.item(),\n",
    "                #    'step': global_step,\n",
    "                #    'epoch': epoch\n",
    "                #})\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                \n",
    "#                # Evaluation round\n",
    "#                division_step = (n_train // (10 * batch_size))\n",
    "#                if division_step > 0:\n",
    "#                    if global_step % division_step == 0:\n",
    "#                        histograms = {}\n",
    "#                        for tag, value in net.named_parameters():\n",
    "#                            tag = tag.replace('/', '.')\n",
    "#                            histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "#                            histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "#\n",
    "#                        val_score = evaluate(net, val_loader, device)\n",
    "#                        scheduler.step(val_score)\n",
    "#\n",
    "#                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "#                        experiment.log({\n",
    "#                            'learning rate': optimizer.param_groups[0]['lr'],\n",
    "#                            'validation Dice': val_score,\n",
    "#                            'images': wandb.Image(images[0].cpu()),\n",
    "#                            'masks': {\n",
    "#                                'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "#                                'pred': wandb.Image(masks_pred.argmax(dim=1)[0].float().cpu()),\n",
    "#                            },\n",
    "#                            'step': global_step,\n",
    "#                            'epoch': epoch,\n",
    "#                            **histograms\n",
    "#                        })\n",
    "#\n",
    "        val_score = evaluate(net,val_loader, device)\n",
    "        print(val_score)\n",
    "        print(epoch_loss/n_train)\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0478b74-66e6-482c-b4d5-33c91751a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\thanh/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a13821043648c78882e071ae7410e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████████████████████████| 1400/1400 [04:22<00:00,  5.34img/s, loss (batch)=0.659]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5867, device='cuda:0')\n",
      "0.2600370811059007\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████| 1400/1400 [04:05<00:00,  5.71img/s, loss (batch)=0.0634]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5932, device='cuda:0')\n",
      "0.18701699178324946\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████████████████████████████| 1400/1400 [04:09<00:00,  5.62img/s, loss (batch)=0.0674]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6081, device='cuda:0')\n",
      "0.1532199166743833\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████| 1400/1400 [04:04<00:00,  5.72img/s, loss (batch)=0.0306]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4958, device='cuda:0')\n",
      "0.1381645401022979\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|███████████████████████████████████████████| 1400/1400 [04:05<00:00,  5.71img/s, loss (batch)=0.00213]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4267, device='cuda:0')\n",
      "0.12430743845325196\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|███████████████████████████████████████████| 1400/1400 [04:04<00:00,  5.72img/s, loss (batch)=0.00797]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4283, device='cuda:0')\n",
      "0.11372364565471539\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████████████████████████████| 1400/1400 [04:04<00:00,  5.73img/s, loss (batch)=0.0113]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5087, device='cuda:0')\n",
      "0.1040942569213647\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████████████████████████████████████████| 1400/1400 [04:03<00:00,  5.75img/s, loss (batch)=0.377]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4108, device='cuda:0')\n",
      "0.09513723054521377\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████████████████████████████| 1400/1400 [04:05<00:00,  5.70img/s, loss (batch)=0.0211]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4214, device='cuda:0')\n",
      "0.08628506282238049\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████████████████████████████| 1400/1400 [04:06<00:00,  5.69img/s, loss (batch)=0.173]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4169, device='cuda:0')\n",
      "0.08063722700580456\n"
     ]
    }
   ],
   "source": [
    "classes = 5\n",
    "bilinear = False\n",
    "loadstate = False\n",
    "load = './checkpoints/Base-UNET-Focal1LossFlip/checkpoint_epoch20.pth'\n",
    "start_epoch = 1\n",
    "epochs = 10\n",
    "batch_size = 1\n",
    "lr = 1e-6\n",
    "scale = 1\n",
    "val = 50\n",
    "amp = False\n",
    "save_checkpoint = True\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = 'cuda'\n",
    "    #logging.info(f'Using device {device}')\n",
    "\n",
    "    # Change here to adapt to your data\n",
    "    # n_channels=3 for RGB images\n",
    "    # n_classes is the number of probabilities you want to get per pixel\n",
    "    #net = UNet(n_channels=3, n_classes = classes, bilinear=bilinear)\n",
    "    net = smp.Unet(\n",
    "        encoder_name='mobilenet_v2',\n",
    "        encoder_depth=5,\n",
    "        encoder_weights='imagenet',\n",
    "        decoder_use_batchnorm=False,\n",
    "        decoder_channels=(1024,512,256, 128, 64),\n",
    "        decoder_attention_type=None,\n",
    "        in_channels=3,\n",
    "        classes=5,\n",
    "        activation=None,\n",
    "        aux_params=None\n",
    "    )\n",
    "    \n",
    "    #logging.info(f'Network:\\n'\n",
    "    #             f'\\t{net.n_channels} input channels\\n'\n",
    "    #             f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "    #             f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "    if loadstate:\n",
    "        net.load_state_dict(torch.load(load, map_location=device))\n",
    "        logging.info(f'Model loaded from {load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    train_net(net=net,\n",
    "                  start_epoch = start_epoch,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  learning_rate=lr,\n",
    "                  device=device,\n",
    "                  img_scale=scale,\n",
    "                  val_percent=val / 100,\n",
    "                  amp=amp,\n",
    "                  save_checkpoint = save_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862c0a2-7b1e-49bf-83cb-9435d5df2f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
